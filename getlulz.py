#!/usr/bin/env python
#-*-coding: utf-8 -*-
import urllib2, re, sys, optparse

if __name__=="__main__":
	parser = optparse.OptionParser("usage: %prog [options] [url]")
	parser.add_option("-f", "--file", dest="file", type="string",help="Use this, if you want HTML output.")
	# тынц
	(options, args) = parser.parse_args()
	# url для getdata(), file для to_file()
	global url,file
	url,file=args[0],options.file
	
explode_url = re.compile(r'[\w\-\.]+\.*')
jru_regexp = re.compile('a href="(.*(?:jpg|jpeg|png|gif|pdf))"')
wakaba_r = re.compile('''["']*/[a-z-_]+/src/[^+]*?['"]''')
krautchan_r = re.compile('''["']*/download/.*?['"]''')


def uniq(seq):
# функция uniq() находит совпадающие элементы в массиве, и выдает новый массив, без совпадающих элементов
    checked = []
    for i in seq:
        if i not in checked:
            checked.append(i)
    return checked
	
def mystrip(arr):
# функция mystrip. Принимает в качестве аргумента массив, содержащий выдранные ссылки на изображение. Возвращает массив с элементами без символа ковычек (")
# например, есть массив arr['"http://foo/bar.jpg"','"http://example.com/foo/bar.png"']
# обработав данный массив, функция возвратит следующий массив: result['http://foo/bar.jpg','http://example.com/foo/bar.png']
	ret = []
	for i in arr:
		i = i.strip('"').strip("'")
		ret.append(i)
	return ret

def getdata(url):
# получает страницу по адресу url, и помещает ее в глобальную переменную raw
	global raw
	usock = urllib2.urlopen(url)
	raw = usock.read()
	# print raw
	usock.close()

def dvach():
	result = []
	data_re = wakaba_r.findall(raw)
	data_uniq = mystrip(data_re)
	data_strip = uniq(data_uniq)
	for i in data_strip:
		result.append("http://2-ch.ru"+i)
	return result
	
def forchan():
	result = []
	data_re = wakaba_r.findall(raw)
	data_uniq = mystrip(data_re)
	data_strip = uniq(data_uniq)
	for i in data_strip:
		result.append("http://images.4chan.org"+i)
	return result
	
def krautchan():
	result = []
	data_re = krautchan_r.findall(raw)
	data_uniq = uniq(data_re)
	data_strip = mystrip(data_uniq)
	for i in data_strip:
		result.append("http://krautchan.net"+i)
	return result
	
def nullchan():
	result = []
	data_re = wakaba_r.findall(raw)
	data_uniq = mystrip(data_re)
	data_strip = uniq(data_uniq)
	for i in data_strip:
		result.append("http://0chan.ru"+i)
	return result

def jru():
	result = []
	data_re = jru_regexp.findall(raw)
	data_uniq = uniq(data_re)
	data_strip = mystrip(data_uniq)
	result=data_strip
	return result
#
# здесь две функции: обе принимают в качестве аргумента массив со ссылками (об этом заботятся функции такие как jru(), dvach()) но выдают разное содержимое
# to_stdout каждый элемент массива (ссылку) печатает с новой строки в stdout
# to_file делает HTML с картинками. А еще эта функция должна уметь определять по filename html это или нет, и если html писать в виде HTML, а если нет -- писать то же что и в stdout, но только в указанный файл # ниасилил - сложная теория, блин
#
def to_stdout(data_arr):
	for i in data_arr:
		print i
		
def to_file(data_arr,filename):
	html = ""
	# верх
	html += '<html><head><title>lulzparser</title><head><body>\n\n<h1>generated by <a href="http://github.com/artemy/lulzparser/">lulparser</a></h1>\n\n'
	for i in data_arr:
		# запихиваем картинки внутрь HTML страницы
		html += '<p><input type="text" value="' + i + '" size="' + str(len(i)) + '"></p>\n<p><img src="' + i + '"></p>\n\n'
	# низ
	html += '</body></html>'
	f = open('./'+filename, 'w')
	f.write(html)
	f.close

getdata(url)
domain = explode_url.findall(url)[1]
if (domain == "chatlogs.jabber.ru" or domain == "www.chatlogs.jabber.ru"): type = 1
if (domain == "2-ch.ru" or domain == "www.2-ch.ru"): type = 2
if (domain == "0chan.ru" or domain == "www.0chan.ru"): type = 3
if (domain == "boards.4chan.org" or domain == "www.boards.4chan.org"): type = 4
if (domain == "krautchan.net" or domain == "www.krautchan.net"): type = 5
if type==1:
	tmp=jru()
elif type==2:
	tmp=dvach()
elif type==3:
	tmp=nullchan()
elif type==4:
	tmp=forchan()
elif type==5:
	tmp=krautchan()
else:
	print "Error"
	sys.exit(1)
if file:
	to_file(tmp,file)
else:
	to_stdout(tmp)

